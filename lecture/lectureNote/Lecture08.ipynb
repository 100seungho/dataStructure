{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps and Hash Tables\n",
    "- Announcement\n",
    "    - Final Project: Web scrapping and visualization. \n",
    "    - Make-up Class: \n",
    "- Review\n",
    "- Input and Output\n",
    "- Map\n",
    "- Hash Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "- Singly Linked List\n",
    "    - Attribute: `element`, `next`\n",
    "    - Pros: Memory allocation doesn't have to be consecutive.\n",
    "- Doubly Linked List\n",
    "    - Attribute:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Console Input and Output\n",
    "- files are  typically accessed in Python beginning with a call to built-in function, named `open`,  that returns a proxy for interactions with  the underlying file.\n",
    "\n",
    "### Example\n",
    "`fp = open('sample.txt')` attempts to open a file named `sample.txt`...\n",
    "\n",
    "## the open funciton accepts an optional second parameter  that determines  the access mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python File I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp  = open('text.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp  = open('text.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp  = open('output.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write('This is a sample output txt file!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write('How are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp =  open('output1.txt', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write('This is a sample output txt file!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.write('How are you?\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = 'http://www.crummy.com/software/BeautifulSoup/'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\n",
      "\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "\n",
      "<html>\n",
      "<head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "<meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      "</head>\n",
      "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n",
      "<div align=\"center\">\n",
      "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
      "<p>\"A tremendous boon.\" -- Python411 Podcast</p>\n",
      "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
      "<p><small>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "<p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p></small></p>\n",
      "</div>\n",
      "<p><i>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>.</i></p> If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.\n",
      "\n",
      "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "<ol>\n",
      "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "<li>Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "<li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "</li></li></li></ol>\n",
      "<p>Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "<p>Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "<p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
      "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
      "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.8.1</a> (October 6, 2019). You can install Beautiful Soup 4 with\n",
      "<code>pip install beautifulsoup4</code>.\n",
      "\n",
      "<p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "<code>python-bs4</code> package (for Python 2) or the\n",
      "<code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
      "available as the <code>python-beautifulsoup4</code> package.\n",
      "\n",
      "<p>Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the <code>bs4/</code> directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using <code>2to3</code>.)\n",
      "\n",
      "<p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "\n",
      "<h3>Beautiful Soup 3</h3>\n",
      "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "\n",
      "<p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>\n",
      "<p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
      "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
      "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
      "and as <code>python-BeautifulSoup</code> in Fedora.\n",
      "\n",
      "<p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "<p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
      "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
      "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "<ul>\n",
      "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "<li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "<li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "<li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</li></li></li></li></li></li></ul>\n",
      "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>.\n",
      "\n",
      "<h2>Development</h2>\n",
      "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>.<hr/><table><tr><td valign=\"top\">\n",
      "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Saturday, November 09 2019, 16:18:48 Nowhere Standard Time and last built on Friday, November 15 2019, 02:00:01 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2019 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></p></td></tr></table></p></p></p></p></p></p></p></p></p></p></p></p></p></p></p></body></html><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--><td valign=\"top\"><p><b>Document tree:</b>\n",
      "<dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n",
      "</dd></dl>\n",
      "</dd></dl>\n",
      "\n",
      "\n",
      "Site Search:\n",
      "\n",
      "<form action=\"/search/\" method=\"get\">\n",
      "<input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "</form>\n",
      "</p></td>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\n",
      "\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
      "<html>\n",
      " <head>\n",
      "  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "  <title>\n",
      "   Beautiful Soup: We called him Tortoise because he taught us.\n",
      "  </title>\n",
      "  <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "  <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "  <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "  <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "  <meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      " </head>\n",
      " <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "  <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/>\n",
      "  <br/>\n",
      "  <p>\n",
      "   You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.\n",
      "  </p>\n",
      "  <div align=\"center\">\n",
      "   <a href=\"bs4/download/\">\n",
      "    <h1>\n",
      "     Beautiful Soup\n",
      "    </h1>\n",
      "   </a>\n",
      "   <p>\n",
      "    \"A tremendous boon.\" -- Python411 Podcast\n",
      "   </p>\n",
      "   <p>\n",
      "    [\n",
      "    <a href=\"#Download\">\n",
      "     Download\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"bs4/doc/\">\n",
      "     Documentation\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"#HallOfFame\">\n",
      "     Hall of Fame\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"https://code.launchpad.net/beautifulsoup\">\n",
      "     Source\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">\n",
      "     Changelog\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "     Discussion group\n",
      "    </a>\n",
      "    |\n",
      "    <a href=\"zine/\">\n",
      "     Zine\n",
      "    </a>\n",
      "    ]\n",
      "   </p>\n",
      "   <p>\n",
      "    <small>\n",
      "     If you use Beautiful Soup as part of your work, please consider a\n",
      "     <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "      Tidelift subscription\n",
      "     </a>\n",
      "     . This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "     <p>\n",
      "      If Beautiful Soup is useful to you on a personal level, you might like to read\n",
      "      <a href=\"zine/\">\n",
      "       <i>\n",
      "        Tool Safety\n",
      "       </i>\n",
      "      </a>\n",
      "      , a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\n",
      "     </p>\n",
      "    </small>\n",
      "   </p>\n",
      "  </div>\n",
      "  <p>\n",
      "   <i>\n",
      "    If you have questions, send them to\n",
      "    <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\n",
      "     the discussion\n",
      "group\n",
      "    </a>\n",
      "    . If you find a bug,\n",
      "    <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "     file it on Launchpad\n",
      "    </a>\n",
      "    .\n",
      "   </i>\n",
      "  </p>\n",
      "  If it's a security vulnerability, report it confidentially through\n",
      "  <a href=\"https://tidelift.com/security\">\n",
      "   Tidelift\n",
      "  </a>\n",
      "  .\n",
      "  <p>\n",
      "   Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "   <ol>\n",
      "    <li>\n",
      "     Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "     <li>\n",
      "      Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "      <li>\n",
      "       Beautiful Soup sits on top of popular Python parsers like\n",
      "       <a href=\"http://lxml.de/\">\n",
      "        lxml\n",
      "       </a>\n",
      "       and\n",
      "       <a href=\"http://code.google.com/p/html5lib/\">\n",
      "        html5lib\n",
      "       </a>\n",
      "       , allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "      </li>\n",
      "     </li>\n",
      "    </li>\n",
      "   </ol>\n",
      "   <p>\n",
      "    Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class\n",
      "    <tt>\n",
      "     externalLink\n",
      "    </tt>\n",
      "    \", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "    <p>\n",
      "     Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "     <p>\n",
      "      Interested?\n",
      "      <a href=\"bs4/doc/\">\n",
      "       Read more.\n",
      "      </a>\n",
      "      <a name=\"Download\">\n",
      "       <h2>\n",
      "        Download Beautiful Soup\n",
      "       </h2>\n",
      "      </a>\n",
      "      <p>\n",
      "       The current release is\n",
      "       <a href=\"bs4/download/\">\n",
      "        Beautiful Soup\n",
      "4.8.1\n",
      "       </a>\n",
      "       (October 6, 2019). You can install Beautiful Soup 4 with\n",
      "       <code>\n",
      "        pip install beautifulsoup4\n",
      "       </code>\n",
      "       .\n",
      "       <p>\n",
      "        In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "        <code>\n",
      "         python-bs4\n",
      "        </code>\n",
      "        package (for Python 2) or the\n",
      "        <code>\n",
      "         python3-bs4\n",
      "        </code>\n",
      "        package (for Python 3). In Fedora it's\n",
      "available as the\n",
      "        <code>\n",
      "         python-beautifulsoup4\n",
      "        </code>\n",
      "        package.\n",
      "        <p>\n",
      "         Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the\n",
      "         <code>\n",
      "          bs4/\n",
      "         </code>\n",
      "         directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using\n",
      "         <code>\n",
      "          2to3\n",
      "         </code>\n",
      "         .)\n",
      "         <p>\n",
      "          Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "          <h3>\n",
      "           Beautiful Soup 3\n",
      "          </h3>\n",
      "          <p>\n",
      "           Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "           <p>\n",
      "            <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">\n",
      "             Here's\n",
      "the Beautiful Soup 3 documentation.\n",
      "            </a>\n",
      "            <p>\n",
      "             The current and hopefully final release of Beautiful Soup 3 is\n",
      "             <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">\n",
      "              3.2.2\n",
      "             </a>\n",
      "             (October 5,\n",
      "2019). It's the\n",
      "             <code>\n",
      "              BeautifulSoup\n",
      "             </code>\n",
      "             package on pip. It's also\n",
      "available as\n",
      "             <code>\n",
      "              python-beautifulsoup\n",
      "             </code>\n",
      "             in Debian and Ubuntu,\n",
      "and as\n",
      "             <code>\n",
      "              python-BeautifulSoup\n",
      "             </code>\n",
      "             in Fedora.\n",
      "             <p>\n",
      "              Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "              <p>\n",
      "               Beautiful Soup 3, like Beautiful Soup 4, is\n",
      "               <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">\n",
      "                supported through Tidelift\n",
      "               </a>\n",
      "               .\n",
      "              </p>\n",
      "              <a name=\"HallOfFame\">\n",
      "               <h2>\n",
      "                Hall of Fame\n",
      "               </h2>\n",
      "              </a>\n",
      "              <p>\n",
      "               Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "               <ul>\n",
      "                <li>\n",
      "                 <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\n",
      "                  \"Movable\n",
      " Type\"\n",
      "                 </a>\n",
      "                 , a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "                 <li>\n",
      "                  Reddit uses Beautiful Soup to\n",
      "                  <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">\n",
      "                   parse\n",
      "a page that's been linked to and find a representative image\n",
      "                  </a>\n",
      "                  .\n",
      "                  <li>\n",
      "                   Alexander Harrowell uses Beautiful Soup to\n",
      "                   <a href=\"http://www.harrowell.org.uk/viktormap.html\">\n",
      "                    track the business\n",
      " activities\n",
      "                   </a>\n",
      "                   of an arms merchant.\n",
      "                   <li>\n",
      "                    The developers of Python itself used Beautiful Soup to\n",
      "                    <a href=\"http://svn.python.org/view/tracker/importer/\">\n",
      "                     migrate the Python\n",
      "bug tracker from Sourceforge to Roundup\n",
      "                    </a>\n",
      "                    .\n",
      "                    <li>\n",
      "                     The\n",
      "                     <a href=\"http://www2.ljworld.com/\">\n",
      "                      Lawrence Journal-World\n",
      "                     </a>\n",
      "                     uses Beautiful Soup to\n",
      "                     <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">\n",
      "                      gather\n",
      "statewide election results\n",
      "                     </a>\n",
      "                     .\n",
      "                     <li>\n",
      "                      The\n",
      "                      <a href=\"http://esrl.noaa.gov/gsd/fab/\">\n",
      "                       NOAA's Forecast\n",
      "Applications Branch\n",
      "                      </a>\n",
      "                      uses Beautiful Soup in\n",
      "                      <a href=\"http://laps.noaa.gov/topograbber/\">\n",
      "                       TopoGrabber\n",
      "                      </a>\n",
      "                      , a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "                     </li>\n",
      "                    </li>\n",
      "                   </li>\n",
      "                  </li>\n",
      "                 </li>\n",
      "                </li>\n",
      "               </ul>\n",
      "               <p>\n",
      "                If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or\n",
      "                <a href=\"http://groups.google.com/group/beautifulsoup/\">\n",
      "                 the discussion\n",
      "group\n",
      "                </a>\n",
      "                .\n",
      "                <h2>\n",
      "                 Development\n",
      "                </h2>\n",
      "                <p>\n",
      "                 Development happens at\n",
      "                 <a href=\"https://launchpad.net/beautifulsoup\">\n",
      "                  Launchpad\n",
      "                 </a>\n",
      "                 . You can\n",
      "                 <a href=\"https://code.launchpad.net/beautifulsoup/\">\n",
      "                  get the source\n",
      "code\n",
      "                 </a>\n",
      "                 or\n",
      "                 <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\n",
      "                  file\n",
      "bugs\n",
      "                 </a>\n",
      "                 .\n",
      "                 <hr/>\n",
      "                 <table>\n",
      "                  <tr>\n",
      "                   <td valign=\"top\">\n",
      "                    <p>\n",
      "                     This document (\n",
      "                     <a href=\"/source/software/BeautifulSoup/index.bhtml\">\n",
      "                      source\n",
      "                     </a>\n",
      "                     ) is part of Crummy, the webspace of\n",
      "                     <a href=\"/self/\">\n",
      "                      Leonard Richardson\n",
      "                     </a>\n",
      "                     (\n",
      "                     <a href=\"/self/contact.html\">\n",
      "                      contact information\n",
      "                     </a>\n",
      "                     ). It was last modified on Saturday, November 09 2019, 16:18:48 Nowhere Standard Time and last built on Friday, November 15 2019, 02:00:01 Nowhere Standard Time.\n",
      "                    </p>\n",
      "                    <p>\n",
      "                     <table class=\"licenseText\">\n",
      "                      <tr>\n",
      "                       <td>\n",
      "                        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "                         <img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/>\n",
      "                        </a>\n",
      "                       </td>\n",
      "                       <td valign=\"top\">\n",
      "                        Crummy is © 1996-2019 Leonard Richardson. Unless otherwise noted, all text licensed under a\n",
      "                        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\n",
      "                         Creative Commons License\n",
      "                        </a>\n",
      "                        .\n",
      "                       </td>\n",
      "                      </tr>\n",
      "                     </table>\n",
      "                    </p>\n",
      "                   </td>\n",
      "                  </tr>\n",
      "                 </table>\n",
      "                </p>\n",
      "               </p>\n",
      "              </p>\n",
      "             </p>\n",
      "            </p>\n",
      "           </p>\n",
      "          </p>\n",
      "         </p>\n",
      "        </p>\n",
      "       </p>\n",
      "      </p>\n",
      "     </p>\n",
      "    </p>\n",
      "   </p>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "<!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>-->\n",
      "<td valign=\"top\">\n",
      " <p>\n",
      "  <b>\n",
      "   Document tree:\n",
      "  </b>\n",
      "  <dl>\n",
      "   <dd>\n",
      "    <a href=\"http://www.crummy.com/\">\n",
      "     http://www.crummy.com/\n",
      "    </a>\n",
      "    <dl>\n",
      "     <dd>\n",
      "      <a href=\"http://www.crummy.com/software/\">\n",
      "       software/\n",
      "      </a>\n",
      "      <dl>\n",
      "       <dd>\n",
      "        <a href=\"http://www.crummy.com/software/BeautifulSoup/\">\n",
      "         BeautifulSoup/\n",
      "        </a>\n",
      "       </dd>\n",
      "      </dl>\n",
      "     </dd>\n",
      "    </dl>\n",
      "   </dd>\n",
      "  </dl>\n",
      "  Site Search:\n",
      "  <form action=\"/search/\" method=\"get\">\n",
      "   <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
      "  </form>\n",
      " </p>\n",
      "</td>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\\n\"http://www.w3.org/TR/REC-html40/transitional.dtd\"',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
       " <title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
       " <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
       " <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       " <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
       " <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
       " <meta content=\"Leonard Richardson\" name=\"author\"/>\n",
       " </head>\n",
       " <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
       " <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
       " <p>You didn't write that awful page. You're just trying to get some\n",
       " data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
       " saving programmers hours or days of work on quick-turnaround\n",
       " screen scraping projects.</p>\n",
       " <div align=\"center\">\n",
       " <a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
       " <p>\"A tremendous boon.\" -- Python411 Podcast</p>\n",
       " <p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
       " <p><small>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
       " <p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p></small></p>\n",
       " </div>\n",
       " <p><i>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
       " group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>.</i></p> If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.\n",
       " \n",
       " <p>Beautiful Soup is a Python library designed for quick turnaround\n",
       " projects like screen-scraping. Three features make it powerful:\n",
       " \n",
       " <ol>\n",
       " <li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
       " for navigating, searching, and modifying a parse tree: a toolkit for\n",
       " dissecting a document and extracting what you need. It doesn't take\n",
       " much code to write an application\n",
       " \n",
       " <li>Beautiful Soup automatically converts incoming documents to\n",
       " Unicode and outgoing documents to UTF-8. You don't have to think\n",
       " about encodings, unless the document doesn't specify an encoding and\n",
       " Beautiful Soup can't detect one. Then you just have to specify the\n",
       " original encoding.\n",
       " \n",
       " <li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
       " to try out different parsing strategies or trade speed for\n",
       " flexibility.\n",
       " \n",
       " </li></li></li></ol>\n",
       " <p>Beautiful Soup parses anything you give it, and does the tree\n",
       " traversal stuff for you. You can tell it \"Find all the links\", or\n",
       " \"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
       " links whose urls match \"foo.com\", or \"Find the table heading that's\n",
       " got bold text, then give me that text.\"\n",
       " \n",
       " <p>Valuable data that was once locked up in poorly-designed websites\n",
       " is now within your reach. Projects that would have taken hours take\n",
       " only minutes with Beautiful Soup.\n",
       " \n",
       " <p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
       " <a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
       " <p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
       " 4.8.1</a> (October 6, 2019). You can install Beautiful Soup 4 with\n",
       " <code>pip install beautifulsoup4</code>.\n",
       " \n",
       " <p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
       " <code>python-bs4</code> package (for Python 2) or the\n",
       " <code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
       " available as the <code>python-beautifulsoup4</code> package.\n",
       " \n",
       " <p>Beautiful Soup is licensed under the MIT license, so you can also\n",
       " download the tarball, drop the <code>bs4/</code> directory into almost\n",
       " any Python application (or into your library path) and start using it\n",
       " immediately. (If you want to do this under Python 3, you will need to\n",
       " manually convert the code using <code>2to3</code>.)\n",
       " \n",
       " <p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
       " 3. Support for Python 2 will be discontinued on or after December 31,\n",
       " 2020—one year after the Python 2 sunsetting date.\n",
       " \n",
       " <h3>Beautiful Soup 3</h3>\n",
       " <p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
       " from May 2006 to March 2012. It does not support Python 3 and it will\n",
       " be discontinued on or after December 31, 2020—one year after the\n",
       " Python 2 sunsetting date. If you have any active projects using\n",
       " Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
       " your Python 3 conversion.\n",
       " \n",
       " <p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
       " the Beautiful Soup 3 documentation.</a>\n",
       " <p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
       " 2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
       " available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
       " and as <code>python-BeautifulSoup</code> in Fedora.\n",
       " \n",
       " <p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
       " \n",
       " <p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
       " <a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
       " <p>Over the years, Beautiful Soup has been used in hundreds of\n",
       " different projects. There's no way I can list them all, but I want to\n",
       " highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
       " these projects interesting, but it did make their completion easier:\n",
       " \n",
       " <ul>\n",
       " <li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
       "  Type\"</a>, a work of digital art on display in the lobby of the New\n",
       "  York Times building, uses Beautiful Soup to scrape news feeds.\n",
       " \n",
       " <li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
       " a page that's been linked to and find a representative image</a>.\n",
       " \n",
       " <li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
       "  activities</a> of an arms merchant.\n",
       " \n",
       " <li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
       " bug tracker from Sourceforge to Roundup</a>.\n",
       " \n",
       " <li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
       " uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
       " statewide election results</a>.\n",
       " \n",
       " <li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
       " Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
       " downloading \"high resolution USGS datasets.\"\n",
       " \n",
       " </li></li></li></li></li></li></ul>\n",
       " <p>If you've used Beautiful Soup in a project you'd like me to know\n",
       " about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
       " group</a>.\n",
       " \n",
       " <h2>Development</h2>\n",
       " <p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
       " code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
       " bugs</a>.<hr/><table><tr><td valign=\"top\">\n",
       " <p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Saturday, November 09 2019, 16:18:48 Nowhere Standard Time and last built on Friday, November 15 2019, 02:00:01 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2019 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></p></td></tr></table></p></p></p></p></p></p></p></p></p></p></p></p></p></p></p></body></html>,\n",
       " '<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>',\n",
       " <td valign=\"top\"><p><b>Document tree:</b>\n",
       " <dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n",
       " </dd></dl>\n",
       " </dd></dl>\n",
       " \n",
       " \n",
       " Site Search:\n",
       " \n",
       " <form action=\"/search/\" method=\"get\">\n",
       " <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
       " </form>\n",
       " </p></td>,\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.Tag,\n",
       " bs4.element.Comment,\n",
       " bs4.element.Tag,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.NavigableString]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(item) for item in list(soup.children)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(soup.children)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "<meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      "</head>\n",
      "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n",
      "<div align=\"center\">\n",
      "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
      "<p>\"A tremendous boon.\" -- Python411 Podcast</p>\n",
      "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
      "<p><small>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "<p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p></small></p>\n",
      "</div>\n",
      "<p><i>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>.</i></p> If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.\n",
      "\n",
      "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "<ol>\n",
      "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "<li>Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "<li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "</li></li></li></ol>\n",
      "<p>Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "<p>Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "<p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
      "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
      "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.8.1</a> (October 6, 2019). You can install Beautiful Soup 4 with\n",
      "<code>pip install beautifulsoup4</code>.\n",
      "\n",
      "<p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "<code>python-bs4</code> package (for Python 2) or the\n",
      "<code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
      "available as the <code>python-beautifulsoup4</code> package.\n",
      "\n",
      "<p>Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the <code>bs4/</code> directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using <code>2to3</code>.)\n",
      "\n",
      "<p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "\n",
      "<h3>Beautiful Soup 3</h3>\n",
      "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "\n",
      "<p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>\n",
      "<p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
      "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
      "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
      "and as <code>python-BeautifulSoup</code> in Fedora.\n",
      "\n",
      "<p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "<p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
      "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
      "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "<ul>\n",
      "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "<li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "<li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "<li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</li></li></li></li></li></li></ul>\n",
      "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>.\n",
      "\n",
      "<h2>Development</h2>\n",
      "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>.<hr/><table><tr><td valign=\"top\">\n",
      "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Saturday, November 09 2019, 16:18:48 Nowhere Standard Time and last built on Friday, November 15 2019, 02:00:01 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2019 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></p></td></tr></table></p></p></p></p></p></p></p></p></p></p></p></p></p></p></p></body></html>\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.NavigableString,\n",
       " bs4.element.Tag,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.Tag]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(item) for item in list(html.children)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
      "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
      "<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
      "<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
      "<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
      "<meta content=\"Leonard Richardson\" name=\"author\"/>\n",
      "</head>\n"
     ]
    }
   ],
   "source": [
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
      "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n",
      "<div align=\"center\">\n",
      "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
      "<p>\"A tremendous boon.\" -- Python411 Podcast</p>\n",
      "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://bazaar.launchpad.net/%7Eleonardr/beautifulsoup/bs4/view/head:/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
      "<p><small>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
      "<p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p></small></p>\n",
      "</div>\n",
      "<p><i>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
      "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>.</i></p> If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.\n",
      "\n",
      "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
      "projects like screen-scraping. Three features make it powerful:\n",
      "\n",
      "<ol>\n",
      "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
      "for navigating, searching, and modifying a parse tree: a toolkit for\n",
      "dissecting a document and extracting what you need. It doesn't take\n",
      "much code to write an application\n",
      "\n",
      "<li>Beautiful Soup automatically converts incoming documents to\n",
      "Unicode and outgoing documents to UTF-8. You don't have to think\n",
      "about encodings, unless the document doesn't specify an encoding and\n",
      "Beautiful Soup can't detect one. Then you just have to specify the\n",
      "original encoding.\n",
      "\n",
      "<li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
      "to try out different parsing strategies or trade speed for\n",
      "flexibility.\n",
      "\n",
      "</li></li></li></ol>\n",
      "<p>Beautiful Soup parses anything you give it, and does the tree\n",
      "traversal stuff for you. You can tell it \"Find all the links\", or\n",
      "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
      "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
      "got bold text, then give me that text.\"\n",
      "\n",
      "<p>Valuable data that was once locked up in poorly-designed websites\n",
      "is now within your reach. Projects that would have taken hours take\n",
      "only minutes with Beautiful Soup.\n",
      "\n",
      "<p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
      "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
      "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
      "4.8.1</a> (October 6, 2019). You can install Beautiful Soup 4 with\n",
      "<code>pip install beautifulsoup4</code>.\n",
      "\n",
      "<p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
      "<code>python-bs4</code> package (for Python 2) or the\n",
      "<code>python3-bs4</code> package (for Python 3). In Fedora it's\n",
      "available as the <code>python-beautifulsoup4</code> package.\n",
      "\n",
      "<p>Beautiful Soup is licensed under the MIT license, so you can also\n",
      "download the tarball, drop the <code>bs4/</code> directory into almost\n",
      "any Python application (or into your library path) and start using it\n",
      "immediately. (If you want to do this under Python 3, you will need to\n",
      "manually convert the code using <code>2to3</code>.)\n",
      "\n",
      "<p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python\n",
      "3. Support for Python 2 will be discontinued on or after December 31,\n",
      "2020—one year after the Python 2 sunsetting date.\n",
      "\n",
      "<h3>Beautiful Soup 3</h3>\n",
      "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
      "from May 2006 to March 2012. It does not support Python 3 and it will\n",
      "be discontinued on or after December 31, 2020—one year after the\n",
      "Python 2 sunsetting date. If you have any active projects using\n",
      "Beautiful Soup 3, you should migrate to Beautiful Soup 4 as part of\n",
      "your Python 3 conversion.\n",
      "\n",
      "<p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
      "the Beautiful Soup 3 documentation.</a>\n",
      "<p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
      "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
      "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
      "and as <code>python-BeautifulSoup</code> in Fedora.\n",
      "\n",
      "<p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
      "\n",
      "<p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
      "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
      "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
      "different projects. There's no way I can list them all, but I want to\n",
      "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
      "these projects interesting, but it did make their completion easier:\n",
      "\n",
      "<ul>\n",
      "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "<li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "<li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "<li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "</li></li></li></li></li></li></ul>\n",
      "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
      "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
      "group</a>.\n",
      "\n",
      "<h2>Development</h2>\n",
      "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
      "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
      "bugs</a>.<hr/><table><tr><td valign=\"top\">\n",
      "<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Saturday, November 09 2019, 16:18:48 Nowhere Standard Time and last built on Friday, November 15 2019, 02:00:01 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2019 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></p></td></tr></table></p></p></p></p></p></p></p></p></p></p></p></p></p></p></p></body>\n"
     ]
    }
   ],
   "source": [
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5d92371add32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchlildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "[type(item) for item in list(body.chlildren)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(body.children)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>You didn't write that awful page. You're just trying to get some\n",
      "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
      "saving programmers hours or days of work on quick-turnaround\n",
      "screen scraping projects.</p>\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "url = 'https://forecast.weather.gov/MapClick.php?lat=40.78232000000003&lon=-73.96541999999994'\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_conditions = soup.find(id='current-conditions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"panel panel-default\" id=\"current-conditions\">\n",
      "<!-- Current Conditions header row -->\n",
      "<div class=\"panel-heading\">\n",
      "<div>\n",
      "<b>Current conditions at</b>\n",
      "<h2 class=\"panel-title\">New York City, Central Park (KNYC)</h2>\n",
      "<span class=\"smallTxt\"><b>Lat: </b>40.78°N<b>Lon: </b>73.97°W<b>Elev: </b>154ft.</span>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"panel-body\" id=\"current-conditions-body\">\n",
      "<!-- Graphic and temperatures -->\n",
      "<div class=\"pull-left\" id=\"current_conditions-summary\">\n",
      "<img alt=\"\" class=\"pull-left\" src=\"newimages/large/nsct.png\"/>\n",
      "<p class=\"myforecast-current\">Fair</p>\n",
      "<p class=\"myforecast-current-lrg\">42°F</p>\n",
      "<p class=\"myforecast-current-sm\">6°C</p>\n",
      "</div>\n",
      "<div class=\"pull-left\" id=\"current_conditions_detail\">\n",
      "<table>\n",
      "<tr>\n",
      "<td class=\"text-right\"><b>Humidity</b></td>\n",
      "<td>47%</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"text-right\"><b>Wind Speed</b></td>\n",
      "<td>Vrbl 5 mph</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"text-right\"><b>Barometer</b></td>\n",
      "<td>30.32 in (1026.0 mb)</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"text-right\"><b>Dewpoint</b></td>\n",
      "<td>23°F (-5°C)</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td class=\"text-right\"><b>Visibility</b></td>\n",
      "<td>10.00 mi</td>\n",
      "</tr>\n",
      "<tr><td class=\"text-right\"><b>Wind Chill</b></td><td>39°F (4°C)</td></tr> <tr>\n",
      "<td class=\"text-right\"><b>Last update</b></td>\n",
      "<td>\n",
      "                14 Nov 9:51 pm EST            </td>\n",
      "</tr>\n",
      "</table>\n",
      "</div>\n",
      "<div id=\"current_conditions_station\">\n",
      "<div class=\"current-conditions-extra\">\n",
      "<!-- Right hand section -->\n",
      "<p class=\"moreInfo\"><b>More Information:</b></p><p><a href=\"https://www.weather.gov/okx/\" id=\"localWFO\" title=\"New York, NY\"><span class=\"hideText\">Local</span> Forecast Office</a><a href=\"obslocal.php?warnzone=NYZ072&amp;local_place=Central Park NY&amp;zoneid=EST&amp;offset=18000\" id=\"moreWx\">More Local Wx</a><a href=\"//www.weather.gov/data/obhistory/KNYC.html\" id=\"3dayHist\">3 Day History</a><a href=\"//mobile.weather.gov/index.php?lat=40.7823&amp;lon=-73.9654&amp;unit=0&amp;lg=english\" id=\"mobileWxLink\">Mobile Weather</a><a href=\"MapClick.php?lat=40.7823&amp;lon=-73.9654&amp;unit=0&amp;lg=english&amp;FcstType=graphical\" id=\"wxGraph\">Hourly <span class=\"hideText\">Weather </span>Forecast</a></p> </div>\n",
      "<!-- /current_conditions_station -->\n",
      "</div>\n",
      "<!-- /current-conditions-body -->\n",
      "</div>\n",
      "<!-- /Current Conditions -->\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(current_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"panel panel-default\" id=\"current-conditions\">\n",
      " <!-- Current Conditions header row -->\n",
      " <div class=\"panel-heading\">\n",
      "  <div>\n",
      "   <b>\n",
      "    Current conditions at\n",
      "   </b>\n",
      "   <h2 class=\"panel-title\">\n",
      "    New York City, Central Park (KNYC)\n",
      "   </h2>\n",
      "   <span class=\"smallTxt\">\n",
      "    <b>\n",
      "     Lat:\n",
      "    </b>\n",
      "    40.78°N\n",
      "    <b>\n",
      "     Lon:\n",
      "    </b>\n",
      "    73.97°W\n",
      "    <b>\n",
      "     Elev:\n",
      "    </b>\n",
      "    154ft.\n",
      "   </span>\n",
      "  </div>\n",
      " </div>\n",
      " <div class=\"panel-body\" id=\"current-conditions-body\">\n",
      "  <!-- Graphic and temperatures -->\n",
      "  <div class=\"pull-left\" id=\"current_conditions-summary\">\n",
      "   <img alt=\"\" class=\"pull-left\" src=\"newimages/large/nsct.png\"/>\n",
      "   <p class=\"myforecast-current\">\n",
      "    Fair\n",
      "   </p>\n",
      "   <p class=\"myforecast-current-lrg\">\n",
      "    42°F\n",
      "   </p>\n",
      "   <p class=\"myforecast-current-sm\">\n",
      "    6°C\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"pull-left\" id=\"current_conditions_detail\">\n",
      "   <table>\n",
      "    <tr>\n",
      "     <td class=\"text-right\">\n",
      "      <b>\n",
      "       Humidity\n",
      "      </b>\n",
      "     </td>\n",
      "     <td>\n",
      "      47%\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td class=\"text-right\">\n",
      "      <b>\n",
      "       Wind Speed\n",
      "      </b>\n",
      "     </td>\n",
      "     <td>\n",
      "      Vrbl 5 mph\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td class=\"text-right\">\n",
      "      <b>\n",
      "       Barometer\n",
      "      </b>\n",
      "     </td>\n",
      "     <td>\n",
      "      30.32 in (1026.0 mb)\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td class=\"text-right\">\n",
      "      <b>\n",
      "       Dewpoint\n",
      "      </b>\n",
      "     </td>\n",
      "     <td>\n",
      "      23°F (-5°C)\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td class=\"text-right\">\n",
      "      <b>\n",
      "       Visibility\n",
      "      </b>\n",
      "     </td>\n",
      "     <td>\n",
      "      10.00 mi\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td class=\"text-right\">\n",
      "      <b>\n",
      "       Wind Chill\n",
      "      </b>\n",
      "     </td>\n",
      "     <td>\n",
      "      39°F (4°C)\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td class=\"text-right\">\n",
      "      <b>\n",
      "       Last update\n",
      "      </b>\n",
      "     </td>\n",
      "     <td>\n",
      "      14 Nov 9:51 pm EST\n",
      "     </td>\n",
      "    </tr>\n",
      "   </table>\n",
      "  </div>\n",
      "  <div id=\"current_conditions_station\">\n",
      "   <div class=\"current-conditions-extra\">\n",
      "    <!-- Right hand section -->\n",
      "    <p class=\"moreInfo\">\n",
      "     <b>\n",
      "      More Information:\n",
      "     </b>\n",
      "    </p>\n",
      "    <p>\n",
      "     <a href=\"https://www.weather.gov/okx/\" id=\"localWFO\" title=\"New York, NY\">\n",
      "      <span class=\"hideText\">\n",
      "       Local\n",
      "      </span>\n",
      "      Forecast Office\n",
      "     </a>\n",
      "     <a href=\"obslocal.php?warnzone=NYZ072&amp;local_place=Central Park NY&amp;zoneid=EST&amp;offset=18000\" id=\"moreWx\">\n",
      "      More Local Wx\n",
      "     </a>\n",
      "     <a href=\"//www.weather.gov/data/obhistory/KNYC.html\" id=\"3dayHist\">\n",
      "      3 Day History\n",
      "     </a>\n",
      "     <a href=\"//mobile.weather.gov/index.php?lat=40.7823&amp;lon=-73.9654&amp;unit=0&amp;lg=english\" id=\"mobileWxLink\">\n",
      "      Mobile Weather\n",
      "     </a>\n",
      "     <a href=\"MapClick.php?lat=40.7823&amp;lon=-73.9654&amp;unit=0&amp;lg=english&amp;FcstType=graphical\" id=\"wxGraph\">\n",
      "      Hourly\n",
      "      <span class=\"hideText\">\n",
      "       Weather\n",
      "      </span>\n",
      "      Forecast\n",
      "     </a>\n",
      "    </p>\n",
      "   </div>\n",
      "   <!-- /current_conditions_station -->\n",
      "  </div>\n",
      "  <!-- /current-conditions-body -->\n",
      " </div>\n",
      " <!-- /Current Conditions -->\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(current_conditions.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_class = current_conditions.find_all(class_='panel-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h2 class=\"panel-title\">New York City, Central Park (KNYC)</h2>]\n"
     ]
    }
   ],
   "source": [
    "print(current_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_conditions_summary = soup.find(id = 'current_conditions-summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"pull-left\" id=\"current_conditions-summary\">\n",
      "<img alt=\"\" class=\"pull-left\" src=\"newimages/large/nsct.png\"/>\n",
      "<p class=\"myforecast-current\">Fair</p>\n",
      "<p class=\"myforecast-current-lrg\">42°F</p>\n",
      "<p class=\"myforecast-current-sm\">6°C</p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(current_conditions_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fair', '42°F', '6°C']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.get_text() for item in current_conditions_summary.find_all('p')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M['k'] = 1\n",
    "M['b'] = 4\n",
    "M['u'] = 2\n",
    "M['v'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dict_keyiterator object at 0x10c911598>\n"
     ]
    }
   ],
   "source": [
    "print(iter(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-162e74b03121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'x'"
     ]
    }
   ],
   "source": [
    "M['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(M.get('f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(M.get('f', 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(M.get('v', 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del M['v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.pop('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['b', 'u'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([4, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('b', 4), ('u', 2)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.setdefault('b', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.setdefault('a', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('b', 4), ('u', 2), ('a', 1)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.popitem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('b', 4), ('u', 2)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = {'c':7, 'z':11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M == M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M != M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.update(M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('b', 4), ('u', 2), ('c', 7), ('z', 11)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example : counting char frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent char is  \n",
      "Its number of occurences is  0\n"
     ]
    }
   ],
   "source": [
    "for piece in open('text.txt', 'r').read().lower().split():\n",
    "    for c in piece:\n",
    "        if c.isalpha():\n",
    "            freq[c] = 1 + freq.get(c, 0)\n",
    "            \n",
    "max_char = ''\n",
    "max_count = 0\n",
    "for (k, v) in freq.items():\n",
    "    if v > max_count:\n",
    "        max_char = k\n",
    "        max_count = v\n",
    "        \n",
    "print('The most frequent char is ', max_char)\n",
    "print('Its number of occurences is ', max_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hash Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
